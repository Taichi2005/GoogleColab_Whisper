{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/notebooks/%E3%80%90%E5%AE%8C%E6%88%90%E7%89%88%E3%80%91URL%E3%81%8B%E3%82%89%E9%AB%98%E7%B2%BE%E5%BA%A6%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%EF%BC%86Gemini%E5%87%A6%E7%90%86%E5%AE%9F%E8%A1%8C%EF%BC%88%E3%83%97%E3%83%AC%E3%82%A4%E3%83%AA%E3%82%B9%E3%83%88%E5%AF%BE%E5%BF%9C%E7%89%88%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOfqH4Yzj3Si"
      },
      "outputs": [],
      "source": [
        "### **【完成版】動画URLから高精度文字起こし＆Gemini要約 実行スクリプト**\n",
        "\n",
        "#以下の3つのセルを上から順番に実行してください。\n",
        "\n",
        "#### **セル1: 環境構築**\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# セル1: 環境構築\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUが有効になっているかを確認\n",
        "print(\"▼ GPUの確認\")\n",
        "!nvidia-smi\n",
        "\n",
        "# 必要なライブラリとツールをインストール\n",
        "# yt-dlp: 様々なサイトから動画や音声をダウンロードするツール\n",
        "# faster-whisper: 高速化されたWhisperモデル\n",
        "# google-generativeai: Gemini APIを使用するためのライブラリ\n",
        "# ffmpeg: 動画・音声の処理・変換に必須のツール\n",
        "print(\"\\n▼ 必要なライブラリとツールのインストール\")\n",
        "!pip install -U yt-dlp -q\n",
        "!pip install faster-whisper==1.0.3 -q\n",
        "!pip install google-genai -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "!apt-get update && apt-get install -y ffmpeg -qq\n",
        "\n",
        "print(\"\\n✅ 環境構築が完了しました。\")\n",
        "print(\"次のセルに進んでGoogle Driveに接続してください。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **セル2: Google Driveへの接続 (任意)**\n",
        "#文字起こししたテキストファイルをGoogle Driveに保存したい場合に、このセルを実行してGoogle Driveをマウント（接続）してください。\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# セル2: Google Driveへの接続\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Driveへの接続が完了しました。\")\n",
        "print(\"最後のセルに進んで、文字起こしを実行してください。\")"
      ],
      "metadata": {
        "id": "gRDxp95dj4XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🚀 URLから高精度文字起こし＆Gemini処理実行（高速化修正版）\n",
        "#@markdown ### 1. 動画のURLと出力先の設定\n",
        "#@markdown ---\n",
        "#@markdown 文字起こししたい動画またはプレイリストのURLを入力してください。\n",
        "video_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 文字起こし結果（.txtファイル）を保存するフォルダのパスを指定します。\n",
        "output_transcript_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **プレイリスト処理**: URLがプレイリストの場合、チェックを入れるとリスト内の全動画を順番に処理します。\n",
        "enable_playlist = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### 2. モデルとパフォーマンス設定\n",
        "#@markdown ---\n",
        "#@markdown **モデル**: `Zoont/...-int8-ct2`は精度を維持しつつ最速・省メモリな**総合推奨モデル**です。\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\", \"large-v2\", \"distil-large-v3\", \"medium\", \"small\", \"base\", \"tiny\"]\n",
        "#@markdown **計算タイプ**: `int8`モデルには`int8_float16`、`float16`モデルには`float16`の組み合わせを推奨します。\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\", \"float32\"]\n",
        "\n",
        "#@markdown ### 3. VAD (音声区間検出) 設定\n",
        "#@markdown ---\n",
        "#@markdown VADを有効にすると、無音区間を自動で除去し、文字起こしの精度を向上させることができます。\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ここで指定したミリ秒以上の無音を「発話の区切り」とみなします。\n",
        "vad_min_silence_duration_ms = 200 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "#@markdown ### 4. 言語設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown 文字起こしする言語を事前に指定する場合に有効にします。指定しない場合は、言語は自動で検出されます。\n",
        "enable_language_specification = False #@param {type:\"boolean\"}\n",
        "#@markdown [言語コード一覧](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py)を参考に、2文字の言語コードを入力してください。（例: ja, en, zh）\n",
        "language_code = \"ja\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 5. 高度な設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown **ビームサイズ (beam_size)**: 文字起こしの精度と速度のトレードオフを調整します。\n",
        "beam_size = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown **中間ファイルのクリーンアップ**: チェックを入れると、処理終了後にダウンロードした音声ファイルを自動で削除します。\n",
        "cleanup_audio_file = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### 6. Geminiによる処理の設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown Geminiを使った処理を有効にする場合は、チェックを入れてAPIキー等を設定してください。\n",
        "enable_gemini_processing = False #@param {type:\"boolean\"}\n",
        "gemini_api_key = \"\" #@param {type:\"string\"}\n",
        "#@markdown **★★★ Geminiモデルをここで選択 ★★★**\n",
        "gemini_model = \"gemini-2.5-flash\" #@param [\"gemini-2.5-pro\", \"gemini-2.5-flash\", \"gemini-2.5-flash-lite\"]\n",
        "#@markdown Geminiの処理結果を保存するフォルダのパスを指定します。\n",
        "output_gemini_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/gemini_outputs\" #@param {type:\"string\"}\n",
        "#@markdown **プロンプト (指示内容)**: Geminiに実行させたいタスクを具体的に入力してください。（例：この内容を箇条書きで3点にまとめて。）\n",
        "gemini_prompt = \"以下の動画書き起こしテキストを、重要なポイントと動画の構成を含めて要約して最大コンテクストで出力してください。\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# --- ここから下は実行コード（編集不要） ---\n",
        "import os\n",
        "import yt_dlp\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import google.generativeai as genai\n",
        "import shutil\n",
        "\n",
        "def get_current_timestamp():\n",
        "    \"\"\"現在時刻を[YYYY-MM-DD HH:MM:SS]形式の文字列で返す\"\"\"\n",
        "    JST = timezone(timedelta(hours=+9))\n",
        "    return datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def process_single_video(video_info, model):\n",
        "    \"\"\"単一の動画を処理する関数\"\"\"\n",
        "    video_id = video_info.get('id', 'default_id')\n",
        "    video_title = video_info.get('title', 'untitled').replace('/', '／')\n",
        "    video_url = video_info.get('webpage_url')\n",
        "\n",
        "    if not video_url and video_id != 'default_id':\n",
        "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "    print(f\"  - 対象: {video_title}\")\n",
        "    print(f\"  - URL: {video_url}\")\n",
        "\n",
        "    temp_audio_dir = \"/content/temp_audio\"\n",
        "    os.makedirs(temp_audio_dir, exist_ok=True)\n",
        "\n",
        "    # 1. 音声ダウンロード\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192'}],\n",
        "        'outtmpl': os.path.join(temp_audio_dir, f'{video_id}.%(ext)s'),\n",
        "        'quiet': True,\n",
        "        'nocheckcertificate': True,\n",
        "        # ▼▼▼【修正】音声ダウンロード時にも 'noplaylist' を適用し、不要な再スキャンを防止 ▼▼▼\n",
        "        'noplaylist': not enable_playlist,\n",
        "    }\n",
        "    audio_file_path = None\n",
        "    full_transcript_text = \"\"\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            # download=Falseのままで問題ありません。\n",
        "            # extract_infoはdownload=Trueが指定された場合、またはダウンロードが必要と判断された場合にダウンロードを実行します。\n",
        "            # ここではpostprocessorsで音声変換を指定しているため、ダウンロードがトリガーされます。\n",
        "            ydl.extract_info(video_url, download=True)\n",
        "            audio_file_path = os.path.join(temp_audio_dir, f'{video_id}.wav')\n",
        "\n",
        "        if not os.path.exists(audio_file_path):\n",
        "            raise FileNotFoundError(\"音声ファイルの生成に失敗しました。\")\n",
        "\n",
        "        # 2. 文字起こし\n",
        "        start_transcribe_time = time.time()\n",
        "        transcribe_options = {\n",
        "            \"beam_size\": beam_size,\n",
        "            \"vad_filter\": use_vad_filter,\n",
        "            \"vad_parameters\": dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "        }\n",
        "        if enable_language_specification and language_code:\n",
        "            transcribe_options[\"language\"] = language_code.strip()\n",
        "\n",
        "        segments, info = model.transcribe(audio_file_path, **transcribe_options)\n",
        "\n",
        "        if not (enable_language_specification and language_code):\n",
        "             print(f\"    -> 検出言語: {info.language} (確率: {info.language_probability:.2f})\")\n",
        "\n",
        "        # 3. 結果保存\n",
        "        safe_title = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in video_title).strip()\n",
        "        output_txt_filename = f\"{video_id}_{safe_title[:50]}.txt\"\n",
        "        transcript_output_path = os.path.join(output_transcript_dir, output_txt_filename)\n",
        "\n",
        "        transcript_lines = []\n",
        "        with open(transcript_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"動画タイトル: {video_title}\\n\")\n",
        "            f.write(f\"URL: {video_url}\\n\")\n",
        "            f.write(f\"文字起こし実行日時: {get_current_timestamp()}\\n\")\n",
        "            f.write(f\"モデル: {model_name} ({compute_type})\\n\")\n",
        "            if enable_language_specification and language_code:\n",
        "                f.write(f\"指定言語: {language_code}\\n\")\n",
        "            else:\n",
        "                f.write(f\"検出言語: {info.language} (確率: {info.language_probability:.2f})\\n\")\n",
        "            f.write(f\"VADフィルター: {'有効' if use_vad_filter else '無効'}\\n\\n---\\n\\n\")\n",
        "\n",
        "            for segment in segments:\n",
        "                line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "                f.write(line)\n",
        "                transcript_lines.append(segment.text.strip())\n",
        "            full_transcript_text = \"\\n\".join(transcript_lines)\n",
        "\n",
        "        end_transcribe_time = time.time()\n",
        "        print(f\"    -> ✅ 文字起こし完了 ({end_transcribe_time - start_transcribe_time:.2f}秒): {os.path.basename(transcript_output_path)}\")\n",
        "\n",
        "        # 4. Gemini処理\n",
        "        if enable_gemini_processing:\n",
        "            if not gemini_api_key:\n",
        "                print(\"    -> ⚠️ Gemini APIキー未設定のためスキップします。\")\n",
        "            elif not full_transcript_text.strip():\n",
        "                print(\"    -> ⚠️ 文字起こし結果が空のためGemini処理をスキップします。\")\n",
        "            else:\n",
        "                try:\n",
        "                    model_gemini = genai.GenerativeModel(gemini_model)\n",
        "                    final_prompt = f\"{gemini_prompt}\\n\\n---\\n\\n以下が対象のテキストです。\\n\\n{full_transcript_text}\"\n",
        "                    response = model_gemini.generate_content(final_prompt)\n",
        "                    gemini_output_text = response.text\n",
        "\n",
        "                    output_filename = f\"{video_id}_{safe_title[:50]}_gemini_output.txt\"\n",
        "                    output_path = os.path.join(output_gemini_dir, output_filename)\n",
        "                    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(f\"■ 元動画タイトル: {video_title}\\n\")\n",
        "                        f.write(f\"■ URL: {video_url}\\n\")\n",
        "                        f.write(f\"■ 実行日時: {get_current_timestamp()}\\n\")\n",
        "                        f.write(f\"■ 使用モデル: {gemini_model}\\n\\n---\\n\\n\")\n",
        "                        f.write(gemini_output_text)\n",
        "                    print(f\"    -> ✅ Gemini処理完了: {os.path.basename(output_path)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"    -> 💥 Gemini APIエラー: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ この動画の処理中にエラーが発生しました: {e}\")\n",
        "    finally:\n",
        "        if cleanup_audio_file and audio_file_path and os.path.exists(audio_file_path):\n",
        "            os.remove(audio_file_path)\n",
        "\n",
        "def run_pipeline():\n",
        "    \"\"\"メインの処理パイプライン\"\"\"\n",
        "    if not video_url:\n",
        "        print(\"❌ エラー: 動画のURLが入力されていません。\")\n",
        "        return\n",
        "\n",
        "    print(f\"{get_current_timestamp()} --- 1. パイプライン開始 ---\")\n",
        "    os.makedirs(output_transcript_dir, exist_ok=True)\n",
        "    if enable_gemini_processing:\n",
        "        os.makedirs(output_gemini_dir, exist_ok=True)\n",
        "        if gemini_api_key:\n",
        "            genai.configure(api_key=gemini_api_key)\n",
        "        else:\n",
        "            print(\"⚠️ Gemini処理が有効ですが、APIキーが設定されていません。\")\n",
        "\n",
        "    temp_audio_dir = \"/content/temp_audio\"\n",
        "    if os.path.exists(temp_audio_dir):\n",
        "        shutil.rmtree(temp_audio_dir)\n",
        "    os.makedirs(temp_audio_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- 2. Whisperモデル '{model_name}' ({compute_type}) をロード中... ---\")\n",
        "    start_load_time = time.time()\n",
        "    try:\n",
        "        model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ モデルのロード中にエラーが発生しました: {e}\")\n",
        "        print(\"   -> ランタイムのタイプがGPUになっているか確認してください。\")\n",
        "        return\n",
        "    end_load_time = time.time()\n",
        "    print(f\"✅ Whisperモデルのロードが完了しました。({end_load_time - start_load_time:.2f}秒)\")\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- 3. 動画情報の取得を開始 ---\")\n",
        "    videos_to_process = []\n",
        "    try:\n",
        "        # ▼▼▼【修正】情報取得時に 'noplaylist' を適用し、単一動画モード時の不要なスキャンを防止 ▼▼▼\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'nocheckcertificate': True,\n",
        "            'ignoreerrors': True,\n",
        "            'noplaylist': not enable_playlist,\n",
        "            'no_warnings': True,\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(video_url, download=False)\n",
        "            if enable_playlist and 'entries' in info:\n",
        "                videos_to_process = [entry for entry in info['entries'] if entry] # Noneのエントリを除外\n",
        "                print(f\"✅ プレイリストを検出しました。{len(videos_to_process)}件の動画を処理します。\")\n",
        "            else:\n",
        "                videos_to_process.append(info)\n",
        "                print(\"✅ 単一動画として処理します。\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ URLからの情報取得に失敗しました: {e}\")\n",
        "        return\n",
        "\n",
        "    total_videos = len(videos_to_process)\n",
        "    if total_videos > 0:\n",
        "        print(f\"\\n{get_current_timestamp()} --- 4. 文字起こしとGemini処理を開始 ---\")\n",
        "        for i, video_info in enumerate(videos_to_process, 1):\n",
        "            print(f\"\\n--- [{i}/{total_videos}] 処理開始 ---\")\n",
        "            process_single_video(video_info, model)\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- 🎉 全ての処理が完了しました ---\")\n",
        "\n",
        "# パイプライン実行\n",
        "run_pipeline()\n"
      ],
      "metadata": {
        "id": "MYicnrLRj8Kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
