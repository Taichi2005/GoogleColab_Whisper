{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/notebooks/%E3%80%90%E5%AE%9F%E9%A8%93%E7%89%88%E3%80%91%E9%AB%98%E6%80%A7%E8%83%BD%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E5%AE%9F%E8%A1%8C%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88_(%E3%83%A2%E3%83%87%E3%83%AB%E3%83%BB%E9%87%8F%E5%AD%90%E5%8C%96_%E9%81%B8%E6%8A%9E%E8%82%A2%E8%BF%BD%E5%8A%A0%E7%89%88).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYdElrdSkbXd"
      },
      "outputs": [],
      "source": [
        "#### **セル1: 環境構築**\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# セル1: 環境構築\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUが有効になっているかを確認\n",
        "print(\"▼ GPUの確認\")\n",
        "!nvidia-smi\n",
        "\n",
        "# faster-whisperと、GPUで動作させるために必要なCUDAライブラリ、Gemini APIライブラリをインストール\n",
        "print(\"\\n▼ 必要なライブラリのインストール\")\n",
        "!pip install faster-whisper==1.0.3 -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "!pip install google-genai -q\n",
        "\n",
        "print(\"\\n✅ 環境構築が完了しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztTnsOy_hL56"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------------------------------------\n",
        "# セル2: Google Driveへの接続\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Driveへの接続が完了しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **セル3: 高性能文字起こし＆Gemini処理 実行セル**\n",
        "#@title 🚀 高性能文字起こし＆Gemini処理 実行セル\n",
        "#@markdown ### 1. Google Driveのパス設定\n",
        "#@markdown ---\n",
        "#@markdown 動画・音声ファイルが保存されているフォルダと、結果を保存するフォルダのパスを指定します。\n",
        "drive_audio_input_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/input_audio\" #@param {type:\"string\"}\n",
        "drive_transcript_output_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 2. モデルとパフォーマンス設定\n",
        "#@markdown ---\n",
        "#@markdown **モデル**: `Zoont/...-int8-ct2`は精度を維持しつつ最速・省メモリな**総合推奨モデル**です。\n",
        "#@markdown **計算タイプ**: `int8`モデルには`int8_float16`、`float16`モデルには`float16`の組み合わせを推奨します。\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\", \"large-v2\", \"distil-large-v3\", \"medium\", \"small\", \"base\", \"tiny\"]\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\", \"float32\"]\n",
        "\n",
        "#@markdown ### 3. VAD (音声区間検出) 設定\n",
        "#@markdown ---\n",
        "#@markdown VADを有効にすると、無音区間を自動で除去し、文字起こしの精度を向上させることができます。\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ここで指定したミリ秒以上の無音を「発話の区切り」とみなします。\n",
        "vad_min_silence_duration_ms = 200 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "#@markdown ### 4. 高度な設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown **ビームサイズ (beam_size)**: 文字起こしの精度と速度のトレードオフを調整します。\n",
        "#@markdown 値を大きくすると精度が向上する可能性がありますが、処理速度は低下します。`faster-whisper`では`5`がバランスの取れた推奨値です。\n",
        "beam_size = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "#@markdown ### 5. Geminiによる処理の設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown Geminiを使った処理を有効にする場合は、チェックを入れてAPIキー等を設定してください。\n",
        "enable_gemini_processing = True #@param {type:\"boolean\"}\n",
        "gemini_api_key = \"AIzaSyCQ5ldVRcvTkdUfYuWqQne0hjzepQxLctU\" #@param {type:\"string\"}\n",
        "gemini_model = \"gemini-2.5-flash\" #@param [\"gemini-2.5-pro\", \"gemini-2.5-flash\", \"gemini-2.5-flash-lite\"]\n",
        "#@markdown Geminiの処理結果を保存するフォルダのパスを指定します。\n",
        "drive_gemini_output_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/gemini_outputs\" #@param {type:\"string\"}\n",
        "#@markdown **プロンプト (指示内容)**: Geminiに実行させたいタスクを具体的に入力してください。（例：この内容から重要なキーワードを10個抽出して。）\n",
        "gemini_prompt = \"以下の会議や講義、対話の書き起こしテキストを、重要なポイントや構成をまとめて要約して最大コンテクストで出力してください。\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# --- ここから下は実行コード（編集不要） ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "import subprocess\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from tqdm.notebook import tqdm\n",
        "import google.generativeai as genai\n",
        "\n",
        "def get_current_timestamp():\n",
        "    \"\"\"現在時刻を[YYYY-MM-DD HH:MM:SS]形式の文字列で返す\"\"\"\n",
        "    JST = timezone(timedelta(hours=+9))\n",
        "    return datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def preprocess_media_file(drive_path, temp_dir):\n",
        "    \"\"\"\n",
        "    メディアファイル（動画・音声）を前処理する関数。\n",
        "    動画の場合はFFmpegで音声を抽出し、一時音声ファイルのパスを返す。\n",
        "    音声の場合はそのままローカルにコピーし、そのパスを返す。\n",
        "    \"\"\"\n",
        "    filename = os.path.basename(drive_path)\n",
        "    base_filename, file_extension = os.path.splitext(filename)\n",
        "\n",
        "    local_media_path = os.path.join(temp_dir, filename)\n",
        "    shutil.copy(drive_path, local_media_path)\n",
        "\n",
        "    supported_video_formats = ['.mp4', '.mov', '.avi', '.wmv', '.mkv', '.flv', '.webm']\n",
        "    if file_extension.lower() in supported_video_formats:\n",
        "        print(f\"  - 動画ファイルを検出。音声の抽出を開始...\")\n",
        "        temp_audio_file = os.path.join(temp_dir, f\"extracted_audio_{base_filename}_{int(time.time()*1000)}.wav\")\n",
        "        try:\n",
        "            subprocess.run(\n",
        "                ['ffmpeg', '-i', local_media_path, '-vn', '-ar', '16000', '-ac', '1', '-y', '-loglevel', 'error', temp_audio_file],\n",
        "                check=True\n",
        "            )\n",
        "            os.remove(local_media_path)\n",
        "            print(f\"  - 音声の抽出が完了 -> {os.path.basename(temp_audio_file)}\")\n",
        "            return temp_audio_file\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"  - 💥 FFmpegエラー ({filename}): 音声の抽出に失敗しました。 {e}\")\n",
        "            if os.path.exists(local_media_path): os.remove(local_media_path)\n",
        "            return None\n",
        "    else:\n",
        "        return local_media_path\n",
        "\n",
        "# 1. 環境設定とディレクトリの準備\n",
        "print(f\"{get_current_timestamp()} --- 1. 環境設定とディレクトリの準備 ---\")\n",
        "os.makedirs(drive_audio_input_dir, exist_ok=True)\n",
        "os.makedirs(drive_transcript_output_dir, exist_ok=True)\n",
        "if enable_gemini_processing:\n",
        "    os.makedirs(drive_gemini_output_dir, exist_ok=True)\n",
        "print(f\"入力フォルダ: {drive_audio_input_dir}\")\n",
        "print(f\"文字起こし出力フォルダ: {drive_transcript_output_dir}\")\n",
        "if enable_gemini_processing:\n",
        "    print(f\"Gemini処理結果の出力フォルダ: {drive_gemini_output_dir}\")\n",
        "\n",
        "\n",
        "# 2. モデルのロード\n",
        "print(f\"\\n{get_current_timestamp()} --- 2. Whisperモデル '{model_name}' ({compute_type}) をロード中... ---\")\n",
        "start_load_time = time.time()\n",
        "model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "end_load_time = time.time()\n",
        "print(f\"✅ Whisperモデルのロードが完了しました。({end_load_time - start_load_time:.2f}秒)\")\n",
        "\n",
        "# 3. 処理対象ファイルの検索\n",
        "print(f\"\\n{get_current_timestamp()} --- 3. 処理対象ファイルの検索 ---\")\n",
        "supported_formats = ['*.mp3', '*.wav', '*.m4a', '*.flac', '*.ogg', '*.opus',\n",
        "                     '*.mp4', '*.mov', '*.avi', '*.wmv', '*.mkv', '*.flv', '*.webm']\n",
        "media_files = []\n",
        "for fmt in supported_formats:\n",
        "    media_files.extend(glob.glob(os.path.join(drive_audio_input_dir, fmt)))\n",
        "\n",
        "if not media_files:\n",
        "    print(\"⚠️ 入力フォルダに処理対象のメディアファイルが見つかりませんでした。\")\n",
        "else:\n",
        "    print(f\"✅ {len(media_files)} 件のメディアファイルを検出しました。\")\n",
        "    # 4. メイン処理ループ\n",
        "    print(f\"\\n{get_current_timestamp()} --- 4. 文字起こし処理開始 ---\")\n",
        "    for media_path_drive in tqdm(media_files, desc=\"全体進捗\"):\n",
        "        start_process_time = time.time()\n",
        "        filename = os.path.basename(media_path_drive)\n",
        "        print(f\"\\n{get_current_timestamp()} ■ 処理開始: {filename}\")\n",
        "\n",
        "        local_audio_path = None\n",
        "        full_transcript_text = \"\"\n",
        "        try:\n",
        "            local_audio_path = preprocess_media_file(media_path_drive, temp_dir='/content/')\n",
        "\n",
        "            if local_audio_path is None:\n",
        "                print(f\"  - ファイル処理をスキップします。\")\n",
        "                continue\n",
        "\n",
        "            # 文字起こし実行\n",
        "            print(f\"  - 文字起こしを実行中... (beam_size: {beam_size}, VAD: {'有効' if use_vad_filter else '無効'})\")\n",
        "            segments, info = model.transcribe(\n",
        "                local_audio_path,\n",
        "                beam_size=beam_size,\n",
        "                vad_filter=use_vad_filter,\n",
        "                vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "            )\n",
        "            print(f\"  - 検出言語: {info.language} (確率: {info.language_probability:.2f})\")\n",
        "\n",
        "            base_filename, _ = os.path.splitext(filename)\n",
        "            output_txt_filename = f\"{base_filename}.txt\"\n",
        "            local_output_path = os.path.join('/content/', output_txt_filename)\n",
        "            drive_output_path = os.path.join(drive_transcript_output_dir, output_txt_filename)\n",
        "\n",
        "            # 処理日時の情報を準備\n",
        "            JST = timezone(timedelta(hours=+9))\n",
        "            now = datetime.now(JST)\n",
        "            timestamp_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            weekdays_jp = [\"月\", \"火\", \"水\", \"木\", \"金\", \"土\", \"日\"]\n",
        "            weekday_str = weekdays_jp[now.weekday()]\n",
        "\n",
        "            with open(local_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                # メタデータ（ヘッダー情報）を書き込む\n",
        "                f.write(f\"元ファイル名: {filename}\\n\")\n",
        "                f.write(f\"処理完了日時: {timestamp_str} ({weekday_str}曜日)\\n\")\n",
        "                f.write(f\"使用モデル: {model_name}\\n\")\n",
        "                f.write(f\"計算タイプ: {compute_type}\\n\")\n",
        "                f.write(f\"VADフィルター: {'有効' if use_vad_filter else '無効'}\\n\\n\")\n",
        "                f.write(\"---\\n\\n\")\n",
        "\n",
        "                # 文字起こし結果を書き込む\n",
        "                transcript_lines = []\n",
        "                for segment in segments:\n",
        "                    line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "                    f.write(line)\n",
        "                    transcript_lines.append(segment.text.strip())\n",
        "                full_transcript_text = \"\\n\".join(transcript_lines)\n",
        "\n",
        "            shutil.move(local_output_path, drive_output_path)\n",
        "            print(f\"  - 文字起こし結果を保存しました: {drive_output_path}\")\n",
        "\n",
        "            # --- ここからGemini処理 ---\n",
        "            if enable_gemini_processing:\n",
        "                print(f\"  - Geminiによる処理を開始...\")\n",
        "                if not gemini_api_key:\n",
        "                    print(\"  - ⚠️ Gemini APIキーが設定されていません。処理をスキップします。\")\n",
        "                elif not full_transcript_text.strip():\n",
        "                     print(\"  - ⚠️ 文字起こし結果が空のため、処理をスキップします。\")\n",
        "                else:\n",
        "                    try:\n",
        "                        genai.configure(api_key=gemini_api_key)\n",
        "                        model_gemini = genai.GenerativeModel(gemini_model)\n",
        "\n",
        "                        # ユーザーが入力した指示と、文字起こしテキストを結合して最終的なプロンプトを作成\n",
        "                        final_prompt = f\"{gemini_prompt}\\n\\n---\\n\\n以下が対象のテキストです。\\n\\n{full_transcript_text}\"\n",
        "\n",
        "                        response = model_gemini.generate_content(final_prompt)\n",
        "                        gemini_output_text = response.text\n",
        "\n",
        "                        # 結果をファイルに保存\n",
        "                        output_filename = f\"{base_filename}_gemini_output.txt\"\n",
        "                        local_output_path = os.path.join('/content/', output_filename)\n",
        "                        drive_output_path = os.path.join(drive_gemini_output_dir, output_filename)\n",
        "\n",
        "                        with open(local_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                            f.write(f\"■ 元ファイル名: {filename}\\n\")\n",
        "                            f.write(f\"■ 処理実行日時: {timestamp_str} ({weekday_str}曜日)\\n\")\n",
        "                            f.write(f\"■ 使用モデル: {gemini_model}\\n\\n\")\n",
        "                            f.write(\"---\\n\\n\")\n",
        "                            f.write(gemini_output_text)\n",
        "\n",
        "                        shutil.move(local_output_path, drive_output_path)\n",
        "                        print(f\"  - ✅ 処理結果を保存しました: {drive_output_path}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  - 💥 Gemini APIエラー: 処理中にエラーが発生しました。 {e}\")\n",
        "            # --- Gemini処理ここまで ---\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - 💥 不明なエラーが発生しました: {e}\")\n",
        "\n",
        "        finally:\n",
        "            if local_audio_path and os.path.exists(local_audio_path):\n",
        "                os.remove(local_audio_path)\n",
        "            end_process_time = time.time()\n",
        "            print(f\"{get_current_timestamp()} ■ 処理完了 ({end_process_time - start_process_time:.2f}秒)\")\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- 🎉 全てのファイルの処理が完了しました ---\")"
      ],
      "metadata": {
        "id": "jIuTskCrlQCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}