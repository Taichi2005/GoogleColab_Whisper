{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/notebooks/%E3%80%90%E5%AE%9F%E9%A8%93%E7%89%88%E3%80%91%E9%AB%98%E6%80%A7%E8%83%BD%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E5%AE%9F%E8%A1%8C%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88_(%E3%83%A2%E3%83%87%E3%83%AB%E3%83%BB%E9%87%8F%E5%AD%90%E5%8C%96_%E9%81%B8%E6%8A%9E%E8%82%A2%E8%BF%BD%E5%8A%A0%E7%89%88).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYdElrdSkbXd"
      },
      "outputs": [],
      "source": [
        "#### **ã‚»ãƒ«1: ç’°å¢ƒæ§‹ç¯‰**\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# ã‚»ãƒ«1: ç’°å¢ƒæ§‹ç¯‰\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ã‚’ç¢ºèª\n",
        "print(\"â–¼ GPUã®ç¢ºèª\")\n",
        "!nvidia-smi\n",
        "\n",
        "# faster-whisperã¨ã€GPUã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã«å¿…è¦ãªCUDAãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€Gemini APIãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "print(\"\\nâ–¼ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\")\n",
        "!pip install faster-whisper==1.0.3 -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "!pip install google-genai -q\n",
        "\n",
        "print(\"\\nâœ… ç’°å¢ƒæ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztTnsOy_hL56"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------------------------------------\n",
        "# ã‚»ãƒ«2: Google Driveã¸ã®æ¥ç¶š\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\nâœ… Google Driveã¸ã®æ¥ç¶šãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **ã‚»ãƒ«3: é«˜æ€§èƒ½æ–‡å­—èµ·ã“ã—ï¼†Geminiå‡¦ç† å®Ÿè¡Œã‚»ãƒ«**\n",
        "#@title ğŸš€ é«˜æ€§èƒ½æ–‡å­—èµ·ã“ã—ï¼†Geminiå‡¦ç† å®Ÿè¡Œã‚»ãƒ«\n",
        "#@markdown ### 1. Google Driveã®ãƒ‘ã‚¹è¨­å®š\n",
        "#@markdown ---\n",
        "#@markdown å‹•ç”»ãƒ»éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã¨ã€çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "drive_audio_input_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/input_audio\" #@param {type:\"string\"}\n",
        "drive_transcript_output_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 2. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š\n",
        "#@markdown ---\n",
        "#@markdown **ãƒ¢ãƒ‡ãƒ«**: `Zoont/...-int8-ct2`ã¯ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤æœ€é€Ÿãƒ»çœãƒ¡ãƒ¢ãƒªãª**ç·åˆæ¨å¥¨ãƒ¢ãƒ‡ãƒ«**ã§ã™ã€‚\n",
        "#@markdown **è¨ˆç®—ã‚¿ã‚¤ãƒ—**: `int8`ãƒ¢ãƒ‡ãƒ«ã«ã¯`int8_float16`ã€`float16`ãƒ¢ãƒ‡ãƒ«ã«ã¯`float16`ã®çµ„ã¿åˆã‚ã›ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\", \"large-v2\", \"distil-large-v3\", \"medium\", \"small\", \"base\", \"tiny\"]\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\", \"float32\"]\n",
        "\n",
        "#@markdown ### 3. VAD (éŸ³å£°åŒºé–“æ¤œå‡º) è¨­å®š\n",
        "#@markdown ---\n",
        "#@markdown VADã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€ç„¡éŸ³åŒºé–“ã‚’è‡ªå‹•ã§é™¤å»ã—ã€æ–‡å­—èµ·ã“ã—ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ã“ã“ã§æŒ‡å®šã—ãŸãƒŸãƒªç§’ä»¥ä¸Šã®ç„¡éŸ³ã‚’ã€Œç™ºè©±ã®åŒºåˆ‡ã‚Šã€ã¨ã¿ãªã—ã¾ã™ã€‚\n",
        "vad_min_silence_duration_ms = 200 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "#@markdown ### 4. é«˜åº¦ãªè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "#@markdown ---\n",
        "#@markdown **ãƒ“ãƒ¼ãƒ ã‚µã‚¤ã‚º (beam_size)**: æ–‡å­—èµ·ã“ã—ã®ç²¾åº¦ã¨é€Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¿æ•´ã—ã¾ã™ã€‚\n",
        "#@markdown å€¤ã‚’å¤§ããã™ã‚‹ã¨ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€å‡¦ç†é€Ÿåº¦ã¯ä½ä¸‹ã—ã¾ã™ã€‚`faster-whisper`ã§ã¯`5`ãŒãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ¨å¥¨å€¤ã§ã™ã€‚\n",
        "beam_size = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "#@markdown ### 5. Geminiã«ã‚ˆã‚‹å‡¦ç†ã®è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "#@markdown ---\n",
        "#@markdown Geminiã‚’ä½¿ã£ãŸå‡¦ç†ã‚’æœ‰åŠ¹ã«ã™ã‚‹å ´åˆã¯ã€ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦APIã‚­ãƒ¼ç­‰ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
        "enable_gemini_processing = True #@param {type:\"boolean\"}\n",
        "gemini_api_key = \"AIzaSyCQ5ldVRcvTkdUfYuWqQne0hjzepQxLctU\" #@param {type:\"string\"}\n",
        "gemini_model = \"gemini-2.5-flash\" #@param [\"gemini-2.5-pro\", \"gemini-2.5-flash\", \"gemini-2.5-flash-lite\"]\n",
        "#@markdown Geminiã®å‡¦ç†çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "drive_gemini_output_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/gemini_outputs\" #@param {type:\"string\"}\n",
        "#@markdown **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (æŒ‡ç¤ºå†…å®¹)**: Geminiã«å®Ÿè¡Œã•ã›ãŸã„ã‚¿ã‚¹ã‚¯ã‚’å…·ä½“çš„ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹ï¼šã“ã®å†…å®¹ã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’10å€‹æŠ½å‡ºã—ã¦ã€‚ï¼‰\n",
        "gemini_prompt = \"ä»¥ä¸‹ã®ä¼šè­°ã‚„è¬›ç¾©ã€å¯¾è©±ã®æ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚„æ§‹æˆã‚’ã¾ã¨ã‚ã¦è¦ç´„ã—ã¦æœ€å¤§ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# --- ã“ã“ã‹ã‚‰ä¸‹ã¯å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ï¼ˆç·¨é›†ä¸è¦ï¼‰ ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "import subprocess\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from tqdm.notebook import tqdm\n",
        "import google.generativeai as genai\n",
        "\n",
        "def get_current_timestamp():\n",
        "    \"\"\"ç¾åœ¨æ™‚åˆ»ã‚’[YYYY-MM-DD HH:MM:SS]å½¢å¼ã®æ–‡å­—åˆ—ã§è¿”ã™\"\"\"\n",
        "    JST = timezone(timedelta(hours=+9))\n",
        "    return datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def preprocess_media_file(drive_path, temp_dir):\n",
        "    \"\"\"\n",
        "    ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå‹•ç”»ãƒ»éŸ³å£°ï¼‰ã‚’å‰å‡¦ç†ã™ã‚‹é–¢æ•°ã€‚\n",
        "    å‹•ç”»ã®å ´åˆã¯FFmpegã§éŸ³å£°ã‚’æŠ½å‡ºã—ã€ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚\n",
        "    éŸ³å£°ã®å ´åˆã¯ãã®ã¾ã¾ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚³ãƒ”ãƒ¼ã—ã€ãã®ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚\n",
        "    \"\"\"\n",
        "    filename = os.path.basename(drive_path)\n",
        "    base_filename, file_extension = os.path.splitext(filename)\n",
        "\n",
        "    local_media_path = os.path.join(temp_dir, filename)\n",
        "    shutil.copy(drive_path, local_media_path)\n",
        "\n",
        "    supported_video_formats = ['.mp4', '.mov', '.avi', '.wmv', '.mkv', '.flv', '.webm']\n",
        "    if file_extension.lower() in supported_video_formats:\n",
        "        print(f\"  - å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã€‚éŸ³å£°ã®æŠ½å‡ºã‚’é–‹å§‹...\")\n",
        "        temp_audio_file = os.path.join(temp_dir, f\"extracted_audio_{base_filename}_{int(time.time()*1000)}.wav\")\n",
        "        try:\n",
        "            subprocess.run(\n",
        "                ['ffmpeg', '-i', local_media_path, '-vn', '-ar', '16000', '-ac', '1', '-y', '-loglevel', 'error', temp_audio_file],\n",
        "                check=True\n",
        "            )\n",
        "            os.remove(local_media_path)\n",
        "            print(f\"  - éŸ³å£°ã®æŠ½å‡ºãŒå®Œäº† -> {os.path.basename(temp_audio_file)}\")\n",
        "            return temp_audio_file\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"  - ğŸ’¥ FFmpegã‚¨ãƒ©ãƒ¼ ({filename}): éŸ³å£°ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚ {e}\")\n",
        "            if os.path.exists(local_media_path): os.remove(local_media_path)\n",
        "            return None\n",
        "    else:\n",
        "        return local_media_path\n",
        "\n",
        "# 1. ç’°å¢ƒè¨­å®šã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™\n",
        "print(f\"{get_current_timestamp()} --- 1. ç’°å¢ƒè¨­å®šã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™ ---\")\n",
        "os.makedirs(drive_audio_input_dir, exist_ok=True)\n",
        "os.makedirs(drive_transcript_output_dir, exist_ok=True)\n",
        "if enable_gemini_processing:\n",
        "    os.makedirs(drive_gemini_output_dir, exist_ok=True)\n",
        "print(f\"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€: {drive_audio_input_dir}\")\n",
        "print(f\"æ–‡å­—èµ·ã“ã—å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {drive_transcript_output_dir}\")\n",
        "if enable_gemini_processing:\n",
        "    print(f\"Geminiå‡¦ç†çµæœã®å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {drive_gemini_output_dir}\")\n",
        "\n",
        "\n",
        "# 2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "print(f\"\\n{get_current_timestamp()} --- 2. Whisperãƒ¢ãƒ‡ãƒ« '{model_name}' ({compute_type}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... ---\")\n",
        "start_load_time = time.time()\n",
        "model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "end_load_time = time.time()\n",
        "print(f\"âœ… Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚({end_load_time - start_load_time:.2f}ç§’)\")\n",
        "\n",
        "# 3. å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢\n",
        "print(f\"\\n{get_current_timestamp()} --- 3. å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œç´¢ ---\")\n",
        "supported_formats = ['*.mp3', '*.wav', '*.m4a', '*.flac', '*.ogg', '*.opus',\n",
        "                     '*.mp4', '*.mov', '*.avi', '*.wmv', '*.mkv', '*.flv', '*.webm']\n",
        "media_files = []\n",
        "for fmt in supported_formats:\n",
        "    media_files.extend(glob.glob(os.path.join(drive_audio_input_dir, fmt)))\n",
        "\n",
        "if not media_files:\n",
        "    print(\"âš ï¸ å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ã«å‡¦ç†å¯¾è±¡ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
        "else:\n",
        "    print(f\"âœ… {len(media_files)} ä»¶ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚\")\n",
        "    # 4. ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—\n",
        "    print(f\"\\n{get_current_timestamp()} --- 4. æ–‡å­—èµ·ã“ã—å‡¦ç†é–‹å§‹ ---\")\n",
        "    for media_path_drive in tqdm(media_files, desc=\"å…¨ä½“é€²æ—\"):\n",
        "        start_process_time = time.time()\n",
        "        filename = os.path.basename(media_path_drive)\n",
        "        print(f\"\\n{get_current_timestamp()} â–  å‡¦ç†é–‹å§‹: {filename}\")\n",
        "\n",
        "        local_audio_path = None\n",
        "        full_transcript_text = \"\"\n",
        "        try:\n",
        "            local_audio_path = preprocess_media_file(media_path_drive, temp_dir='/content/')\n",
        "\n",
        "            if local_audio_path is None:\n",
        "                print(f\"  - ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
        "                continue\n",
        "\n",
        "            # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ\n",
        "            print(f\"  - æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­... (beam_size: {beam_size}, VAD: {'æœ‰åŠ¹' if use_vad_filter else 'ç„¡åŠ¹'})\")\n",
        "            segments, info = model.transcribe(\n",
        "                local_audio_path,\n",
        "                beam_size=beam_size,\n",
        "                vad_filter=use_vad_filter,\n",
        "                vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "            )\n",
        "            print(f\"  - æ¤œå‡ºè¨€èª: {info.language} (ç¢ºç‡: {info.language_probability:.2f})\")\n",
        "\n",
        "            base_filename, _ = os.path.splitext(filename)\n",
        "            output_txt_filename = f\"{base_filename}.txt\"\n",
        "            local_output_path = os.path.join('/content/', output_txt_filename)\n",
        "            drive_output_path = os.path.join(drive_transcript_output_dir, output_txt_filename)\n",
        "\n",
        "            # å‡¦ç†æ—¥æ™‚ã®æƒ…å ±ã‚’æº–å‚™\n",
        "            JST = timezone(timedelta(hours=+9))\n",
        "            now = datetime.now(JST)\n",
        "            timestamp_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            weekdays_jp = [\"æœˆ\", \"ç«\", \"æ°´\", \"æœ¨\", \"é‡‘\", \"åœŸ\", \"æ—¥\"]\n",
        "            weekday_str = weekdays_jp[now.weekday()]\n",
        "\n",
        "            with open(local_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ï¼‰ã‚’æ›¸ãè¾¼ã‚€\n",
        "                f.write(f\"å…ƒãƒ•ã‚¡ã‚¤ãƒ«å: {filename}\\n\")\n",
        "                f.write(f\"å‡¦ç†å®Œäº†æ—¥æ™‚: {timestamp_str} ({weekday_str}æ›œæ—¥)\\n\")\n",
        "                f.write(f\"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}\\n\")\n",
        "                f.write(f\"è¨ˆç®—ã‚¿ã‚¤ãƒ—: {compute_type}\\n\")\n",
        "                f.write(f\"VADãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {'æœ‰åŠ¹' if use_vad_filter else 'ç„¡åŠ¹'}\\n\\n\")\n",
        "                f.write(\"---\\n\\n\")\n",
        "\n",
        "                # æ–‡å­—èµ·ã“ã—çµæœã‚’æ›¸ãè¾¼ã‚€\n",
        "                transcript_lines = []\n",
        "                for segment in segments:\n",
        "                    line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "                    f.write(line)\n",
        "                    transcript_lines.append(segment.text.strip())\n",
        "                full_transcript_text = \"\\n\".join(transcript_lines)\n",
        "\n",
        "            shutil.move(local_output_path, drive_output_path)\n",
        "            print(f\"  - æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {drive_output_path}\")\n",
        "\n",
        "            # --- ã“ã“ã‹ã‚‰Geminiå‡¦ç† ---\n",
        "            if enable_gemini_processing:\n",
        "                print(f\"  - Geminiã«ã‚ˆã‚‹å‡¦ç†ã‚’é–‹å§‹...\")\n",
        "                if not gemini_api_key:\n",
        "                    print(\"  - âš ï¸ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
        "                elif not full_transcript_text.strip():\n",
        "                     print(\"  - âš ï¸ æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã®ãŸã‚ã€å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
        "                else:\n",
        "                    try:\n",
        "                        genai.configure(api_key=gemini_api_key)\n",
        "                        model_gemini = genai.GenerativeModel(gemini_model)\n",
        "\n",
        "                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸæŒ‡ç¤ºã¨ã€æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã—ã¦æœ€çµ‚çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ\n",
        "                        final_prompt = f\"{gemini_prompt}\\n\\n---\\n\\nä»¥ä¸‹ãŒå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚\\n\\n{full_transcript_text}\"\n",
        "\n",
        "                        response = model_gemini.generate_content(final_prompt)\n",
        "                        gemini_output_text = response.text\n",
        "\n",
        "                        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
        "                        output_filename = f\"{base_filename}_gemini_output.txt\"\n",
        "                        local_output_path = os.path.join('/content/', output_filename)\n",
        "                        drive_output_path = os.path.join(drive_gemini_output_dir, output_filename)\n",
        "\n",
        "                        with open(local_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                            f.write(f\"â–  å…ƒãƒ•ã‚¡ã‚¤ãƒ«å: {filename}\\n\")\n",
        "                            f.write(f\"â–  å‡¦ç†å®Ÿè¡Œæ—¥æ™‚: {timestamp_str} ({weekday_str}æ›œæ—¥)\\n\")\n",
        "                            f.write(f\"â–  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {gemini_model}\\n\\n\")\n",
        "                            f.write(\"---\\n\\n\")\n",
        "                            f.write(gemini_output_text)\n",
        "\n",
        "                        shutil.move(local_output_path, drive_output_path)\n",
        "                        print(f\"  - âœ… å‡¦ç†çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {drive_output_path}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  - ğŸ’¥ Gemini APIã‚¨ãƒ©ãƒ¼: å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ {e}\")\n",
        "            # --- Geminiå‡¦ç†ã“ã“ã¾ã§ ---\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - ğŸ’¥ ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "\n",
        "        finally:\n",
        "            if local_audio_path and os.path.exists(local_audio_path):\n",
        "                os.remove(local_audio_path)\n",
        "            end_process_time = time.time()\n",
        "            print(f\"{get_current_timestamp()} â–  å‡¦ç†å®Œäº† ({end_process_time - start_process_time:.2f}ç§’)\")\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- ğŸ‰ å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---\")"
      ],
      "metadata": {
        "id": "jIuTskCrlQCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}