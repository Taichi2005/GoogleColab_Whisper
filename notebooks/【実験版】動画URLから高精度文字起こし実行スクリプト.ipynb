{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/notebooks/%E3%80%90%E5%AE%9F%E9%A8%93%E7%89%88%E3%80%91%E5%8B%95%E7%94%BBURL%E3%81%8B%E3%82%89%E9%AB%98%E7%B2%BE%E5%BA%A6%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E5%AE%9F%E8%A1%8C%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOfqH4Yzj3Si"
      },
      "outputs": [],
      "source": [
        "### **【完成版】動画URLから高精度文字起こし＆Gemini要約 実行スクリプト**\n",
        "\n",
        "#以下の3つのセルを上から順番に実行してください。\n",
        "\n",
        "#### **セル1: 環境構築**\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# セル1: 環境構築\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUが有効になっているかを確認\n",
        "print(\"▼ GPUの確認\")\n",
        "!nvidia-smi\n",
        "\n",
        "# 必要なライブラリとツールをインストール\n",
        "# yt-dlp: 様々なサイトから動画や音声をダウンロードするツール\n",
        "# faster-whisper: 高速化されたWhisperモデル\n",
        "# google-generativeai: Gemini APIを使用するためのライブラリ\n",
        "# ffmpeg: 動画・音声の処理・変換に必須のツール\n",
        "print(\"\\n▼ 必要なライブラリとツールのインストール\")\n",
        "!pip install -U yt-dlp -q\n",
        "!pip install faster-whisper==1.0.3 -q\n",
        "!pip install google-genai -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "!apt-get update && apt-get install -y ffmpeg -qq\n",
        "\n",
        "print(\"\\n✅ 環境構築が完了しました。\")\n",
        "print(\"次のセルに進んでGoogle Driveに接続してください。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **セル2: Google Driveへの接続 (任意)**\n",
        "#文字起こししたテキストファイルをGoogle Driveに保存したい場合に、このセルを実行してGoogle Driveをマウント（接続）してください。\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# セル2: Google Driveへの接続\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Driveへの接続が完了しました。\")\n",
        "print(\"最後のセルに進んで、文字起こしを実行してください。\")"
      ],
      "metadata": {
        "id": "gRDxp95dj4XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### **セル3: 🚀 URLから高精度文字起こし＆要約実行**\n",
        "\n",
        "#@title 🚀 URLから高精度文字起こし＆要約実行 (Gemini 2.5対応)\n",
        "#@markdown ### 1. 動画のURLと出力先の設定\n",
        "#@markdown ---\n",
        "#@markdown 文字起こししたい動画のURLを入力してください。\n",
        "video_url = \"https://youtu.be/Q_b5C5neo7U?si=bJBuGKKHJzGIkYSs\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 文字起こし結果（.txtファイル）を保存するフォルダのパスを指定します。\n",
        "output_transcript_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 2. モデルとパフォーマンス設定\n",
        "#@markdown ---\n",
        "#@markdown **モデル**: `Zoont/...-int8-ct2`は精度を維持しつつ最速・省メモリな**総合推奨モデル**です。\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\", \"large-v2\", \"distil-large-v3\", \"medium\", \"small\", \"base\", \"tiny\"]\n",
        "#@markdown **計算タイプ**: `int8`モデルには`int8_float16`、`float16`モデルには`float16`の組み合わせを推奨します。\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\", \"float32\"]\n",
        "\n",
        "#@markdown ### 3. VAD (音声区間検出) 設定\n",
        "#@markdown ---\n",
        "#@markdown VADを有効にすると、無音区間を自動で除去し、文字起こしの精度を向上させることができます。\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ここで指定したミリ秒以上の無音を「発話の区切り」とみなします。\n",
        "vad_min_silence_duration_ms = 200 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "#@markdown ### 4. 高度な設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown **ビームサイズ (beam_size)**: 文字起こしの精度と速度のトレードオフを調整します。\n",
        "beam_size = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown **中間ファイルのクリーンアップ**: チェックを入れると、処理終了後にダウンロードした音声ファイルを自動で削除します。\n",
        "cleanup_audio_file = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### 5. Geminiによる要約設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown 文字起こし結果の要約を有効にする場合は、チェックを入れてAPIキー等を設定してください。\n",
        "enable_summarization = True #@param {type:\"boolean\"}\n",
        "gemini_api_key = \"\" #@param {type:\"string\"}\n",
        "gemini_model = \"gemini-2.5-flash\" #@param [\"gemini-2.5-pro\", \"gemini-2.5-flash\", \"gemini-2.5-flash-lite\"]\n",
        "output_summary_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_summary\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# --- ここから下は実行コード（編集不要） ---\n",
        "import os\n",
        "import yt_dlp\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import google.generativeai as genai\n",
        "\n",
        "def get_current_timestamp():\n",
        "    \"\"\"現在時刻を[YYYY-MM-DD HH:MM:SS]形式の文字列で返す\"\"\"\n",
        "    JST = timezone(timedelta(hours=+9))\n",
        "    return datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def run_pipeline():\n",
        "    \"\"\"メインの処理パイプライン\"\"\"\n",
        "    if not video_url:\n",
        "        print(\"❌ エラー: 動画のURLが入力されていません。\")\n",
        "        return\n",
        "\n",
        "    print(f\"{get_current_timestamp()} --- 1. パイプライン開始 ---\")\n",
        "\n",
        "    # 出力ディレクトリの作成\n",
        "    os.makedirs(output_transcript_dir, exist_ok=True)\n",
        "    print(f\"文字起こし出力先: {output_transcript_dir}\")\n",
        "    if enable_summarization:\n",
        "        os.makedirs(output_summary_dir, exist_ok=True)\n",
        "        print(f\"要約出力先: {output_summary_dir}\")\n",
        "\n",
        "\n",
        "    # 一時ダウンロード用ディレクトリの作成\n",
        "    temp_audio_dir = \"/content/temp_audio\"\n",
        "    os.makedirs(temp_audio_dir, exist_ok=True)\n",
        "\n",
        "    # 2. モデルのロード\n",
        "    print(f\"\\n{get_current_timestamp()} --- 2. Whisperモデル '{model_name}' ({compute_type}) をロード中... ---\")\n",
        "    start_load_time = time.time()\n",
        "    try:\n",
        "        model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ モデルのロード中にエラーが発生しました: {e}\")\n",
        "        print(\"   -> ランタイムのタイプがGPUになっているか確認してください。\")\n",
        "        return\n",
        "\n",
        "    end_load_time = time.time()\n",
        "    print(f\"✅ Whisperモデルのロードが完了しました。({end_load_time - start_load_time:.2f}秒)\")\n",
        "\n",
        "    # 3. yt-dlpによる音声のダウンロードと抽出\n",
        "    print(f\"\\n{get_current_timestamp()} --- 3. URLから音声のダウンロードと抽出を開始 ---\")\n",
        "    print(f\"対象URL: {video_url}\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192'}],\n",
        "        'outtmpl': os.path.join(temp_audio_dir, '%(id)s.%(ext)s'),\n",
        "        'quiet': True,\n",
        "        'nocheckcertificate': True,\n",
        "    }\n",
        "\n",
        "    audio_file_path = None\n",
        "    video_title = \"untitled\"\n",
        "    video_id = \"default_id\"\n",
        "    full_transcript_text = \"\"\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(video_url, download=True)\n",
        "            video_id = info.get('id', 'default_id')\n",
        "            video_title = info.get('title', 'untitled').replace('/', '／') # ファイル名に使えない文字を置換\n",
        "            base, _ = os.path.splitext(ydl.prepare_filename(info))\n",
        "            audio_file_path = base + \".wav\"\n",
        "\n",
        "        if not os.path.exists(audio_file_path):\n",
        "            raise FileNotFoundError(\"音声ファイルの生成に失敗しました。\")\n",
        "\n",
        "        print(f\"✅ 音声ファイルの準備が完了しました: {os.path.basename(audio_file_path)}\")\n",
        "        print(f\"   動画タイトル: {video_title}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 音声のダウンロードまたは変換中にエラーが発生しました: {e}\")\n",
        "        return\n",
        "\n",
        "    # 4. 文字起こし処理\n",
        "    print(f\"\\n{get_current_timestamp()} --- 4. 文字起こし処理開始 ---\")\n",
        "    start_transcribe_time = time.time()\n",
        "    try:\n",
        "        print(f\"  - 設定 (beam_size: {beam_size}, VAD: {'有効' if use_vad_filter else '無効'})\")\n",
        "        segments, info = model.transcribe(\n",
        "            audio_file_path,\n",
        "            beam_size=beam_size,\n",
        "            vad_filter=use_vad_filter,\n",
        "            vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "        )\n",
        "        print(f\"  - 検出言語: {info.language} (確率: {info.language_probability:.2f})\")\n",
        "\n",
        "        # 5. 結果の保存\n",
        "        # ファイル名に使えない文字を置換し、長さを制限\n",
        "        safe_title = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in video_title).strip()\n",
        "        output_txt_filename = f\"{video_id}_{safe_title[:50]}.txt\"\n",
        "        transcript_output_path = os.path.join(output_transcript_dir, output_txt_filename)\n",
        "\n",
        "        transcript_lines = []\n",
        "        with open(transcript_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"動画タイトル: {video_title}\\n\")\n",
        "            f.write(f\"URL: {video_url}\\n\")\n",
        "            f.write(f\"文字起こし実行日時: {get_current_timestamp()}\\n\")\n",
        "            f.write(f\"モデル: {model_name} ({compute_type})\\n\\n---\\n\\n\")\n",
        "\n",
        "            for segment in segments:\n",
        "                line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "                f.write(line)\n",
        "                transcript_lines.append(segment.text.strip())\n",
        "            full_transcript_text = \"\\n\".join(transcript_lines) # 要約用に全文を結合\n",
        "\n",
        "\n",
        "        end_transcribe_time = time.time()\n",
        "        print(f\"✅ 文字起こしが完了しました。({end_transcribe_time - start_transcribe_time:.2f}秒)\")\n",
        "        print(f\"   -> 結果を保存しました: {transcript_output_path}\")\n",
        "\n",
        "        # --- ここから要約処理 ---\n",
        "        if enable_summarization:\n",
        "            print(f\"\\n{get_current_timestamp()} --- 5. Geminiによる要約を開始 ---\")\n",
        "            if not gemini_api_key:\n",
        "                print(\"  - ⚠️ Gemini APIキーが設定されていません。要約をスキップします。\")\n",
        "            elif not full_transcript_text.strip():\n",
        "                print(\"  - ⚠️ 文字起こし結果が空のため、要約をスキップします。\")\n",
        "            else:\n",
        "                try:\n",
        "                    genai.configure(api_key=gemini_api_key)\n",
        "                    model_gemini = genai.GenerativeModel(gemini_model)\n",
        "                    prompt = f\"以下の動画書き起こしテキストを、重要なポイントと動画の構成を含めて要約して最大コンテクストで出力してください。\\n\\n---\\n\\n{full_transcript_text}\"\n",
        "                    response = model_gemini.generate_content(prompt)\n",
        "                    summary_text = response.text\n",
        "\n",
        "                    # 要約結果をファイルに保存\n",
        "                    summary_filename = f\"{video_id}_{safe_title[:50]}_summary.txt\"\n",
        "                    summary_output_path = os.path.join(output_summary_dir, summary_filename)\n",
        "\n",
        "                    with open(summary_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(f\"■ 元動画タイトル: {video_title}\\n\")\n",
        "                        f.write(f\"■ URL: {video_url}\\n\")\n",
        "                        f.write(f\"■ 要約実行日時: {get_current_timestamp()}\\n\")\n",
        "                        f.write(f\"■ 使用モデル: {gemini_model}\\n\\n---\\n\\n\")\n",
        "                        f.write(summary_text)\n",
        "\n",
        "                    print(f\"  - ✅ 要約結果を保存しました: {summary_output_path}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  - 💥 Gemini APIエラー: 要約中にエラーが発生しました。 {e}\")\n",
        "        # --- 要約処理ここまで ---\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 文字起こし中にエラーが発生しました: {e}\")\n",
        "    finally:\n",
        "        # 6. 中間ファイルのクリーンアップ\n",
        "        if cleanup_audio_file and audio_file_path and os.path.exists(audio_file_path):\n",
        "            os.remove(audio_file_path)\n",
        "            print(f\"\\n{get_current_timestamp()} --- 6. 中間音声ファイルを削除しました ---\")\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- 🎉 全ての処理が完了しました ---\")\n",
        "\n",
        "# パイプライン実行\n",
        "run_pipeline()"
      ],
      "metadata": {
        "id": "MYicnrLRj8Kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}