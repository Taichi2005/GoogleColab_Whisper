{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/notebooks/%E3%80%90%E5%AE%9F%E9%A8%93%E7%89%88%E3%80%91%E5%8B%95%E7%94%BBURL%E3%81%8B%E3%82%89%E9%AB%98%E7%B2%BE%E5%BA%A6%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E5%AE%9F%E8%A1%8C%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOfqH4Yzj3Si"
      },
      "outputs": [],
      "source": [
        "### **ã€å®Œæˆç‰ˆã€‘å‹•ç”»URLã‹ã‚‰é«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—ï¼†Geminiè¦ç´„ å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ**\n",
        "\n",
        "#ä»¥ä¸‹ã®3ã¤ã®ã‚»ãƒ«ã‚’ä¸Šã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "#### **ã‚»ãƒ«1: ç’°å¢ƒæ§‹ç¯‰**\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# ã‚»ãƒ«1: ç’°å¢ƒæ§‹ç¯‰\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ã‚’ç¢ºèª\n",
        "print(\"â–¼ GPUã®ç¢ºèª\")\n",
        "!nvidia-smi\n",
        "\n",
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ„ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# yt-dlp: æ§˜ã€…ãªã‚µã‚¤ãƒˆã‹ã‚‰å‹•ç”»ã‚„éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ„ãƒ¼ãƒ«\n",
        "# faster-whisper: é«˜é€ŸåŒ–ã•ã‚ŒãŸWhisperãƒ¢ãƒ‡ãƒ«\n",
        "# google-generativeai: Gemini APIã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "# ffmpeg: å‹•ç”»ãƒ»éŸ³å£°ã®å‡¦ç†ãƒ»å¤‰æ›ã«å¿…é ˆã®ãƒ„ãƒ¼ãƒ«\n",
        "print(\"\\nâ–¼ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\")\n",
        "!pip install -U yt-dlp -q\n",
        "!pip install faster-whisper==1.0.3 -q\n",
        "!pip install google-genai -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "!apt-get update && apt-get install -y ffmpeg -qq\n",
        "\n",
        "print(\"\\nâœ… ç’°å¢ƒæ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
        "print(\"æ¬¡ã®ã‚»ãƒ«ã«é€²ã‚“ã§Google Driveã«æ¥ç¶šã—ã¦ãã ã•ã„ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **ã‚»ãƒ«2: Google Driveã¸ã®æ¥ç¶š (ä»»æ„)**\n",
        "#æ–‡å­—èµ·ã“ã—ã—ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Driveã«ä¿å­˜ã—ãŸã„å ´åˆã«ã€ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆï¼ˆæ¥ç¶šï¼‰ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# ã‚»ãƒ«2: Google Driveã¸ã®æ¥ç¶š\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\nâœ… Google Driveã¸ã®æ¥ç¶šãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
        "print(\"æœ€å¾Œã®ã‚»ãƒ«ã«é€²ã‚“ã§ã€æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
      ],
      "metadata": {
        "id": "gRDxp95dj4XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### **ã‚»ãƒ«3: ğŸš€ URLã‹ã‚‰é«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å®Ÿè¡Œ**\n",
        "\n",
        "#@title ğŸš€ URLã‹ã‚‰é«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å®Ÿè¡Œ (Gemini 2.5å¯¾å¿œ)\n",
        "#@markdown ### 1. å‹•ç”»ã®URLã¨å‡ºåŠ›å…ˆã®è¨­å®š\n",
        "#@markdown ---\n",
        "#@markdown æ–‡å­—èµ·ã“ã—ã—ãŸã„å‹•ç”»ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\n",
        "video_url = \"https://youtu.be/Q_b5C5neo7U?si=bJBuGKKHJzGIkYSs\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown æ–‡å­—èµ·ã“ã—çµæœï¼ˆ.txtãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
        "output_transcript_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 2. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š\n",
        "#@markdown ---\n",
        "#@markdown **ãƒ¢ãƒ‡ãƒ«**: `Zoont/...-int8-ct2`ã¯ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤æœ€é€Ÿãƒ»çœãƒ¡ãƒ¢ãƒªãª**ç·åˆæ¨å¥¨ãƒ¢ãƒ‡ãƒ«**ã§ã™ã€‚\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\", \"large-v2\", \"distil-large-v3\", \"medium\", \"small\", \"base\", \"tiny\"]\n",
        "#@markdown **è¨ˆç®—ã‚¿ã‚¤ãƒ—**: `int8`ãƒ¢ãƒ‡ãƒ«ã«ã¯`int8_float16`ã€`float16`ãƒ¢ãƒ‡ãƒ«ã«ã¯`float16`ã®çµ„ã¿åˆã‚ã›ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\", \"float32\"]\n",
        "\n",
        "#@markdown ### 3. VAD (éŸ³å£°åŒºé–“æ¤œå‡º) è¨­å®š\n",
        "#@markdown ---\n",
        "#@markdown VADã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€ç„¡éŸ³åŒºé–“ã‚’è‡ªå‹•ã§é™¤å»ã—ã€æ–‡å­—èµ·ã“ã—ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ã“ã“ã§æŒ‡å®šã—ãŸãƒŸãƒªç§’ä»¥ä¸Šã®ç„¡éŸ³ã‚’ã€Œç™ºè©±ã®åŒºåˆ‡ã‚Šã€ã¨ã¿ãªã—ã¾ã™ã€‚\n",
        "vad_min_silence_duration_ms = 200 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "#@markdown ### 4. é«˜åº¦ãªè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "#@markdown ---\n",
        "#@markdown **ãƒ“ãƒ¼ãƒ ã‚µã‚¤ã‚º (beam_size)**: æ–‡å­—èµ·ã“ã—ã®ç²¾åº¦ã¨é€Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¿æ•´ã—ã¾ã™ã€‚\n",
        "beam_size = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown **ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—**: ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨ã€å‡¦ç†çµ‚äº†å¾Œã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã§å‰Šé™¤ã—ã¾ã™ã€‚\n",
        "cleanup_audio_file = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### 5. Geminiã«ã‚ˆã‚‹è¦ç´„è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "#@markdown ---\n",
        "#@markdown æ–‡å­—èµ·ã“ã—çµæœã®è¦ç´„ã‚’æœ‰åŠ¹ã«ã™ã‚‹å ´åˆã¯ã€ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦APIã‚­ãƒ¼ç­‰ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n",
        "enable_summarization = True #@param {type:\"boolean\"}\n",
        "gemini_api_key = \"\" #@param {type:\"string\"}\n",
        "gemini_model = \"gemini-2.5-flash\" #@param [\"gemini-2.5-pro\", \"gemini-2.5-flash\", \"gemini-2.5-flash-lite\"]\n",
        "output_summary_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_summary\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# --- ã“ã“ã‹ã‚‰ä¸‹ã¯å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ï¼ˆç·¨é›†ä¸è¦ï¼‰ ---\n",
        "import os\n",
        "import yt_dlp\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import google.generativeai as genai\n",
        "\n",
        "def get_current_timestamp():\n",
        "    \"\"\"ç¾åœ¨æ™‚åˆ»ã‚’[YYYY-MM-DD HH:MM:SS]å½¢å¼ã®æ–‡å­—åˆ—ã§è¿”ã™\"\"\"\n",
        "    JST = timezone(timedelta(hours=+9))\n",
        "    return datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def run_pipeline():\n",
        "    \"\"\"ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\"\"\"\n",
        "    if not video_url:\n",
        "        print(\"âŒ ã‚¨ãƒ©ãƒ¼: å‹•ç”»ã®URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\")\n",
        "        return\n",
        "\n",
        "    print(f\"{get_current_timestamp()} --- 1. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹ ---\")\n",
        "\n",
        "    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
        "    os.makedirs(output_transcript_dir, exist_ok=True)\n",
        "    print(f\"æ–‡å­—èµ·ã“ã—å‡ºåŠ›å…ˆ: {output_transcript_dir}\")\n",
        "    if enable_summarization:\n",
        "        os.makedirs(output_summary_dir, exist_ok=True)\n",
        "        print(f\"è¦ç´„å‡ºåŠ›å…ˆ: {output_summary_dir}\")\n",
        "\n",
        "\n",
        "    # ä¸€æ™‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
        "    temp_audio_dir = \"/content/temp_audio\"\n",
        "    os.makedirs(temp_audio_dir, exist_ok=True)\n",
        "\n",
        "    # 2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
        "    print(f\"\\n{get_current_timestamp()} --- 2. Whisperãƒ¢ãƒ‡ãƒ« '{model_name}' ({compute_type}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... ---\")\n",
        "    start_load_time = time.time()\n",
        "    try:\n",
        "        model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "        print(\"   -> ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ãŒGPUã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
        "        return\n",
        "\n",
        "    end_load_time = time.time()\n",
        "    print(f\"âœ… Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚({end_load_time - start_load_time:.2f}ç§’)\")\n",
        "\n",
        "    # 3. yt-dlpã«ã‚ˆã‚‹éŸ³å£°ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨æŠ½å‡º\n",
        "    print(f\"\\n{get_current_timestamp()} --- 3. URLã‹ã‚‰éŸ³å£°ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨æŠ½å‡ºã‚’é–‹å§‹ ---\")\n",
        "    print(f\"å¯¾è±¡URL: {video_url}\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192'}],\n",
        "        'outtmpl': os.path.join(temp_audio_dir, '%(id)s.%(ext)s'),\n",
        "        'quiet': True,\n",
        "        'nocheckcertificate': True,\n",
        "    }\n",
        "\n",
        "    audio_file_path = None\n",
        "    video_title = \"untitled\"\n",
        "    video_id = \"default_id\"\n",
        "    full_transcript_text = \"\"\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(video_url, download=True)\n",
        "            video_id = info.get('id', 'default_id')\n",
        "            video_title = info.get('title', 'untitled').replace('/', 'ï¼') # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’ç½®æ›\n",
        "            base, _ = os.path.splitext(ydl.prepare_filename(info))\n",
        "            audio_file_path = base + \".wav\"\n",
        "\n",
        "        if not os.path.exists(audio_file_path):\n",
        "            raise FileNotFoundError(\"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "        print(f\"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ: {os.path.basename(audio_file_path)}\")\n",
        "        print(f\"   å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_title}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ éŸ³å£°ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "        return\n",
        "\n",
        "    # 4. æ–‡å­—èµ·ã“ã—å‡¦ç†\n",
        "    print(f\"\\n{get_current_timestamp()} --- 4. æ–‡å­—èµ·ã“ã—å‡¦ç†é–‹å§‹ ---\")\n",
        "    start_transcribe_time = time.time()\n",
        "    try:\n",
        "        print(f\"  - è¨­å®š (beam_size: {beam_size}, VAD: {'æœ‰åŠ¹' if use_vad_filter else 'ç„¡åŠ¹'})\")\n",
        "        segments, info = model.transcribe(\n",
        "            audio_file_path,\n",
        "            beam_size=beam_size,\n",
        "            vad_filter=use_vad_filter,\n",
        "            vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "        )\n",
        "        print(f\"  - æ¤œå‡ºè¨€èª: {info.language} (ç¢ºç‡: {info.language_probability:.2f})\")\n",
        "\n",
        "        # 5. çµæœã®ä¿å­˜\n",
        "        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆãªã„æ–‡å­—ã‚’ç½®æ›ã—ã€é•·ã•ã‚’åˆ¶é™\n",
        "        safe_title = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in video_title).strip()\n",
        "        output_txt_filename = f\"{video_id}_{safe_title[:50]}.txt\"\n",
        "        transcript_output_path = os.path.join(output_transcript_dir, output_txt_filename)\n",
        "\n",
        "        transcript_lines = []\n",
        "        with open(transcript_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_title}\\n\")\n",
        "            f.write(f\"URL: {video_url}\\n\")\n",
        "            f.write(f\"æ–‡å­—èµ·ã“ã—å®Ÿè¡Œæ—¥æ™‚: {get_current_timestamp()}\\n\")\n",
        "            f.write(f\"ãƒ¢ãƒ‡ãƒ«: {model_name} ({compute_type})\\n\\n---\\n\\n\")\n",
        "\n",
        "            for segment in segments:\n",
        "                line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "                f.write(line)\n",
        "                transcript_lines.append(segment.text.strip())\n",
        "            full_transcript_text = \"\\n\".join(transcript_lines) # è¦ç´„ç”¨ã«å…¨æ–‡ã‚’çµåˆ\n",
        "\n",
        "\n",
        "        end_transcribe_time = time.time()\n",
        "        print(f\"âœ… æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚({end_transcribe_time - start_transcribe_time:.2f}ç§’)\")\n",
        "        print(f\"   -> çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {transcript_output_path}\")\n",
        "\n",
        "        # --- ã“ã“ã‹ã‚‰è¦ç´„å‡¦ç† ---\n",
        "        if enable_summarization:\n",
        "            print(f\"\\n{get_current_timestamp()} --- 5. Geminiã«ã‚ˆã‚‹è¦ç´„ã‚’é–‹å§‹ ---\")\n",
        "            if not gemini_api_key:\n",
        "                print(\"  - âš ï¸ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¦ç´„ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
        "            elif not full_transcript_text.strip():\n",
        "                print(\"  - âš ï¸ æ–‡å­—èµ·ã“ã—çµæœãŒç©ºã®ãŸã‚ã€è¦ç´„ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
        "            else:\n",
        "                try:\n",
        "                    genai.configure(api_key=gemini_api_key)\n",
        "                    model_gemini = genai.GenerativeModel(gemini_model)\n",
        "                    prompt = f\"ä»¥ä¸‹ã®å‹•ç”»æ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¨å‹•ç”»ã®æ§‹æˆã‚’å«ã‚ã¦è¦ç´„ã—ã¦æœ€å¤§ã‚³ãƒ³ãƒ†ã‚¯ã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\\n\\n---\\n\\n{full_transcript_text}\"\n",
        "                    response = model_gemini.generate_content(prompt)\n",
        "                    summary_text = response.text\n",
        "\n",
        "                    # è¦ç´„çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
        "                    summary_filename = f\"{video_id}_{safe_title[:50]}_summary.txt\"\n",
        "                    summary_output_path = os.path.join(output_summary_dir, summary_filename)\n",
        "\n",
        "                    with open(summary_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(f\"â–  å…ƒå‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_title}\\n\")\n",
        "                        f.write(f\"â–  URL: {video_url}\\n\")\n",
        "                        f.write(f\"â–  è¦ç´„å®Ÿè¡Œæ—¥æ™‚: {get_current_timestamp()}\\n\")\n",
        "                        f.write(f\"â–  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {gemini_model}\\n\\n---\\n\\n\")\n",
        "                        f.write(summary_text)\n",
        "\n",
        "                    print(f\"  - âœ… è¦ç´„çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {summary_output_path}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  - ğŸ’¥ Gemini APIã‚¨ãƒ©ãƒ¼: è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ {e}\")\n",
        "        # --- è¦ç´„å‡¦ç†ã“ã“ã¾ã§ ---\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "    finally:\n",
        "        # 6. ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
        "        if cleanup_audio_file and audio_file_path and os.path.exists(audio_file_path):\n",
        "            os.remove(audio_file_path)\n",
        "            print(f\"\\n{get_current_timestamp()} --- 6. ä¸­é–“éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ ---\")\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- ğŸ‰ å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---\")\n",
        "\n",
        "# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ\n",
        "run_pipeline()"
      ],
      "metadata": {
        "id": "MYicnrLRj8Kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}