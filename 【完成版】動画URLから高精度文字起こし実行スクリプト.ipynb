{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2gXUe6ub71TgxCpC6cTsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/%E3%80%90%E5%AE%8C%E6%88%90%E7%89%88%E3%80%91%E5%8B%95%E7%94%BBURL%E3%81%8B%E3%82%89%E9%AB%98%E7%B2%BE%E5%BA%A6%E6%96%87%E5%AD%97%E8%B5%B7%E3%81%93%E3%81%97%E5%AE%9F%E8%A1%8C%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOfqH4Yzj3Si",
        "outputId": "cbf6bf09-6057-4b06-bed3-540416fcd52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▼ GPUの確認\n",
            "Sat Oct 25 13:31:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "▼ 必要なライブラリとツールのインストール\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,816 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,473 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,799 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,389 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Fetched 21.5 MB in 4s (5,016 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "✅ 環境構築が完了しました。\n",
            "次のセルに進んでGoogle Driveに接続してください。\n"
          ]
        }
      ],
      "source": [
        "### **【完成版】動画URLから高精度文字起こし実行スクリプト**\n",
        "\n",
        "#以下の3つのセルを上から順番に実行してください。\n",
        "\n",
        "#### **セル1: 環境構築**\n",
        "#このセルでは、文字起こしに必要なライブラリやツールをすべてインストールします。初回実行時は数分かかることがあります。\n",
        "\n",
        "# セル1: 環境構築\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUが有効になっているかを確認\n",
        "print(\"▼ GPUの確認\")\n",
        "!nvidia-smi\n",
        "\n",
        "# 必要なライブラリとツールをインストール\n",
        "# yt-dlp: 様々なサイトから動画や音声をダウンロードするツール\n",
        "# faster-whisper: 高速化されたWhisperモデル\n",
        "# ffmpeg: 動画・音声の処理・変換に必須のツール\n",
        "print(\"\\n▼ 必要なライブラリとツールのインストール\")\n",
        "!pip install -U yt-dlp -q\n",
        "!pip install faster-whisper==1.0.3 -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "!apt-get update && apt-get install -y ffmpeg -qq\n",
        "\n",
        "print(\"\\n✅ 環境構築が完了しました。\")\n",
        "print(\"次のセルに進んでGoogle Driveに接続してください。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **セル2: Google Driveへの接続 (任意)**\n",
        "#文字起こししたテキストファイルをGoogle Driveに保存したい場合に、このセルを実行してGoogle Driveをマウント（接続）してください。\n",
        "\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# セル2: Google Driveへの接続\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Driveへの接続が完了しました。\")\n",
        "print(\"最後のセルに進んで、文字起こしを実行してください。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRDxp95dj4XH",
        "outputId": "438b71e3-e199-4a20-bfc7-81df88e47a5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "✅ Google Driveへの接続が完了しました。\n",
            "最後のセルに進んで、文字起こしを実行してください。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **セル3: 🚀 URLから高精度文字起こし実行**\n",
        "#ここに動画のURLを入力し、設定を調整してから実行ボタン（▶）を押してください。\n",
        "\n",
        "#@title 🚀 URLから高精度文字起こし実行\n",
        "#@markdown ### 1. 動画のURLと出力先の設定\n",
        "#@markdown ---\n",
        "#@markdown 文字起こししたい動画のURLを入力してください。\n",
        "video_url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown 結果（.txtファイル）を保存するフォルダのパスを指定します。\n",
        "#@markdown **ローカルに保存する場合:** `/content/transcripts` のように入力します。\n",
        "#@markdown **Google Driveに保存する場合:** `/content/drive/MyDrive/transcripts` のように入力します。（セル2の実行が必要です）\n",
        "output_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 2. モデルとパフォーマンス設定\n",
        "#@markdown ---\n",
        "#@markdown **モデル**: `Zoont/...-int8-ct2`は精度を維持しつつ最速・省メモリな**総合推奨モデル**です。\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\", \"large-v2\", \"distil-large-v3\", \"medium\", \"small\", \"base\", \"tiny\"]\n",
        "#@markdown **計算タイプ**: `int8`モデルには`int8_float16`、`float16`モデルには`float16`の組み合わせを推奨します。\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\", \"float32\"]\n",
        "\n",
        "#@markdown ### 3. VAD (音声区間検出) 設定\n",
        "#@markdown ---\n",
        "#@markdown VADを有効にすると、無音区間を自動で除去し、文字起こしの精度を向上させることができます。\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ここで指定したミリ秒以上の無音を「発話の区切り」とみなします。\n",
        "vad_min_silence_duration_ms = 500 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "#@markdown ### 4. 高度な設定（オプション）\n",
        "#@markdown ---\n",
        "#@markdown **ビームサイズ (beam_size)**: 文字起こしの精度と速度のトレードオフを調整します。値を大きくすると精度が向上する可能性がありますが、処理速度は低下します。`faster-whisper`では`5`がバランスの取れた推奨値です。\n",
        "beam_size = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "#@markdown **中間ファイルのクリーンアップ**: チェックを入れると、処理終了後にダウンロードした音声ファイルを自動で削除します。\n",
        "cleanup_audio_file = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# --- ここから下は実行コード（編集不要） ---\n",
        "import os\n",
        "import yt_dlp\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "from datetime import datetime, timezone, timedelta\n",
        "import torch\n",
        "\n",
        "def get_current_timestamp():\n",
        "    \"\"\"現在時刻を[YYYY-MM-DD HH:MM:SS]形式の文字列で返す\"\"\"\n",
        "    JST = timezone(timedelta(hours=+9))\n",
        "    return datetime.now(JST).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def run_pipeline():\n",
        "    \"\"\"メインの処理パイプライン\"\"\"\n",
        "    if not video_url:\n",
        "        print(\"❌ エラー: 動画のURLが入力されていません。\")\n",
        "        return\n",
        "\n",
        "    print(f\"{get_current_timestamp()} --- 1. パイプライン開始 ---\")\n",
        "\n",
        "    # 出力ディレクトリの作成\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"出力先フォルダ: {output_dir}\")\n",
        "\n",
        "    # 一時ダウンロード用ディレクトリの作成\n",
        "    temp_audio_dir = \"/content/temp_audio\"\n",
        "    os.makedirs(temp_audio_dir, exist_ok=True)\n",
        "\n",
        "    # 2. モデルのロード\n",
        "    print(f\"\\n{get_current_timestamp()} --- 2. モデル '{model_name}' ({compute_type}) をロード中... ---\")\n",
        "    start_load_time = time.time()\n",
        "    try:\n",
        "        model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ モデルのロード中にエラーが発生しました: {e}\")\n",
        "        print(\"   -> ランタイムのタイプがGPUになっているか確認してください。\")\n",
        "        return\n",
        "\n",
        "    end_load_time = time.time()\n",
        "    print(f\"✅ モデルのロードが完了しました。({end_load_time - start_load_time:.2f}秒)\")\n",
        "\n",
        "    # 3. yt-dlpによる音声のダウンロードと抽出\n",
        "    print(f\"\\n{get_current_timestamp()} --- 3. URLから音声のダウンロードと抽出を開始 ---\")\n",
        "    print(f\"対象URL: {video_url}\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav', # Whisperが最も得意とするWAV形式に変換\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': os.path.join(temp_audio_dir, '%(id)s.%(ext)s'),\n",
        "        'quiet': True,\n",
        "    }\n",
        "\n",
        "    audio_file_path = None\n",
        "    video_title = \"untitled\"\n",
        "    video_id = \"default_id\"\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(video_url, download=True)\n",
        "            video_id = info.get('id', 'default_id')\n",
        "            video_title = info.get('title', 'untitled')\n",
        "            # 拡張子を.wavに変更したパスを生成\n",
        "            base, _ = os.path.splitext(ydl.prepare_filename(info))\n",
        "            audio_file_path = base + \".wav\"\n",
        "\n",
        "        if not os.path.exists(audio_file_path):\n",
        "            raise FileNotFoundError(\"音声ファイルの生成に失敗しました。\")\n",
        "\n",
        "        print(f\"✅ 音声ファイルの準備が完了しました: {os.path.basename(audio_file_path)}\")\n",
        "        print(f\"   動画タイトル: {video_title}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 音声のダウンロードまたは変換中にエラーが発生しました: {e}\")\n",
        "        return\n",
        "\n",
        "    # 4. 文字起こし処理\n",
        "    print(f\"\\n{get_current_timestamp()} --- 4. 文字起こし処理開始 ---\")\n",
        "    start_transcribe_time = time.time()\n",
        "    try:\n",
        "        print(f\"  - 設定 (beam_size: {beam_size}, VAD: {'有効' if use_vad_filter else '無効'})\")\n",
        "        segments, info = model.transcribe(\n",
        "            audio_file_path,\n",
        "            beam_size=beam_size,\n",
        "            vad_filter=use_vad_filter,\n",
        "            vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "        )\n",
        "        print(f\"  - 検出言語: {info.language} (確率: {info.language_probability:.2f})\")\n",
        "\n",
        "        # 5. 結果の保存\n",
        "        output_txt_filename = f\"{video_id}_{video_title[:50]}.txt\".replace('/','-') # ファイル名に使えない文字を置換\n",
        "        drive_output_path = os.path.join(output_dir, output_txt_filename)\n",
        "\n",
        "        with open(drive_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"動画タイトル: {video_title}\\n\")\n",
        "            f.write(f\"URL: {video_url}\\n\")\n",
        "            f.write(f\"文字起こし実行日時: {get_current_timestamp()}\\n\")\n",
        "            f.write(f\"モデル: {model_name} ({compute_type})\\n\\n---\\n\\n\")\n",
        "\n",
        "            full_text = \"\"\n",
        "            for segment in segments:\n",
        "                line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "                f.write(line)\n",
        "                full_text += segment.text.strip() + \" \"\n",
        "\n",
        "        end_transcribe_time = time.time()\n",
        "        print(f\"✅ 文字起こしが完了しました。({end_transcribe_time - start_transcribe_time:.2f}秒)\")\n",
        "        print(f\"   -> 結果を保存しました: {drive_output_path}\")\n",
        "\n",
        "        print(\"\\n--- 書き起こし結果 (冒頭) ---\")\n",
        "        print(full_text[:500] + \"...\")\n",
        "        print(\"--------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 文字起こし中にエラーが発生しました: {e}\")\n",
        "    finally:\n",
        "        # 6. 中間ファイルのクリーンアップ\n",
        "        if cleanup_audio_file and audio_file_path and os.path.exists(audio_file_path):\n",
        "            os.remove(audio_file_path)\n",
        "            print(f\"\\n{get_current_timestamp()} --- 5. 中間音声ファイルを削除しました ---\")\n",
        "\n",
        "    print(f\"\\n{get_current_timestamp()} --- 🎉 全ての処理が完了しました ---\")\n",
        "\n",
        "# パイプライン実行\n",
        "run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYicnrLRj8Kk",
        "outputId": "99298552-c05a-4d14-b29d-ae8cc8a20759"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-25 22:38:06 --- 1. パイプライン開始 ---\n",
            "出力先フォルダ: /content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\n",
            "\n",
            "2025-10-25 22:38:10 --- 2. モデル 'Zoont/faster-whisper-large-v3-turbo-int8-ct2' (int8_float16) をロード中... ---\n",
            "✅ モデルのロードが完了しました。(0.91秒)\n",
            "\n",
            "2025-10-25 22:38:11 --- 3. URLから音声のダウンロードと抽出を開始 ---\n",
            "対象URL: https://youtu.be/M3AezqTHS2o?si=e4e3OSMcK1B0skRg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] Falling back to generic n function search\n",
            "         player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n",
            "WARNING: [youtube] M3AezqTHS2o: nsig extraction failed: Some formats may be missing\n",
            "         n = PVg62htio8WDXOR7 ; player = https://www.youtube.com/s/player/6e4dbefe/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] M3AezqTHS2o: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] M3AezqTHS2o: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 音声ファイルの準備が完了しました: M3AezqTHS2o.wav\n",
            "   動画タイトル: 【談合】マンション大規模修繕で理事へのキックバック横行？阻止法はあるのか\n",
            "\n",
            "2025-10-25 22:38:28 --- 4. 文字起こし処理開始 ---\n",
            "  - 設定 (beam_size: 5, VAD: 有効)\n",
            "  - 検出言語: ja (確率: 1.00)\n",
            "✅ 文字起こしが完了しました。(86.55秒)\n",
            "   -> 結果を保存しました: /content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts/M3AezqTHS2o_【談合】マンション大規模修繕で理事へのキックバック横行？阻止法はあるのか.txt\n",
            "\n",
            "--- 書き起こし結果 (冒頭) ---\n",
            "マンションを購入してただいま10年目ぐらいなんですが レジネンスのマンションですよね 住むための 中古で今はもう地区30年を超えている状態でして そろそろ大規模修繕3回目をやろうかという話になりまして その中で自分の方が大規模修繕委員に専任されまして ただ過去の大規模修繕の話とかを聞くと 結構1度目と2度目で方式とかがガラッと変わってしまっておりまして 過去の修繕した方も担当もいらっしゃらないということで 担当というのは管理組合の中にいない マンションの修繕委員の経験がいない それに加えて結構いろんなニュースが最近大規模修繕でありましたので ちょっと不安になりましていつも見させていただいていたりします マンションで言いますと結構50個ぐらいの小さいマンションになっておりまして もう本当30年経って1回目2回目と修繕をやっているんですが 1度目がどうやら設計管理方式といって いろいろ業者さんをマンション設計士さんから経由して 何でしょう 協売って言うんですかね 入札みたいな 入札して選んだ状態と 2回目はもともと管理している 建設の管理会社 というところは主導で そこに任せよという形にな...\n",
            "--------------------------\n",
            "\n",
            "2025-10-25 22:39:55 --- 5. 中間音声ファイルを削除しました ---\n",
            "\n",
            "2025-10-25 22:39:55 --- 🎉 全ての処理が完了しました ---\n"
          ]
        }
      ]
    }
  ]
}