{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn8iUor+FjqJs05FXBYXuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taichi2005/GoogleColab_Whisper/blob/main/%E3%80%90%E6%A9%9F%E8%83%BD%E6%8B%A1%E5%BC%B5%E7%89%88%E3%80%91%E6%9C%80%E7%B5%82%E7%A2%BA%E5%AE%9A%E3%82%B3%E3%83%BC%E3%83%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYdElrdSkbXd"
      },
      "outputs": [],
      "source": [
        "# セル1: 環境構築\n",
        "# -------------------------------------------------------------------------------------------\n",
        "# GPUが有効になっているかを確認\n",
        "print(\"▼ GPUの確認\")\n",
        "!nvidia-smi\n",
        "\n",
        "# faster-whisperと、GPUで動作させるために必要なCUDAライブラリをインストール\n",
        "print(\"\\n▼ 必要なライブラリのインストール\")\n",
        "!pip install --upgrade faster-whisper -q\n",
        "!pip install nvidia-cublas-cu12==12.6.4.1 -q\n",
        "!pip install nvidia-cudnn-cu12==9.10.2.21 -q\n",
        "\n",
        "print(\"\\n✅ 環境構築が完了しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztTnsOy_hL56"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------------------------------------\n",
        "# セル2: Google Driveへの接続\n",
        "# -------------------------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Driveへの接続が完了しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🚀【機能拡張版】高性能・多機能 文字起こし実行セル\n",
        "#@markdown ### 1. Google Driveのパス設定\n",
        "#@markdown ---\n",
        "#@markdown 音声や動画ファイルが保存されているフォルダと、結果を保存するフォルダのパスを指定します。\n",
        "drive_audio_input_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/input_audio\" #@param {type:\"string\"}\n",
        "drive_transcript_output_dir = \"/content/drive/MyDrive/Colab/Whisper_Transcripts/output_transcripts\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 2. 処理対象の選択\n",
        "#@markdown ---\n",
        "#@markdown 入力フォルダ内のファイルをどのように処理するか選択してください。\n",
        "processing_mode = \"\\u5168\\u3066\\u306E\\u30D5\\u30A1\\u30A4\\u30EB\\u3092\\u51E6\\u7406\" #@param [\"全てのファイルを処理\", \"特定の１ファイルのみ処理\"]\n",
        "#@markdown ---\n",
        "#@markdown `特定の１ファイルのみ処理` を選択した場合は、下のフィールドに対象のファイル名を入力してください。\n",
        "specific_filename = \"your_audio_file.mp4\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#@markdown ### 3. モデルとパフォーマンス設定\n",
        "#@markdown ---\n",
        "#@markdown **モデル**: `Zoont/faster-whisper-large-v3-turbo-int8-ct2`は、精度を維持しつつメモリ効率を最大化した推奨モデルです。<br>\n",
        "#@markdown **計算タイプ**: `int8_float16`は、int8モデル利用時の推奨設定です。\n",
        "model_name = \"Zoont/faster-whisper-large-v3-turbo-int8-ct2\" #@param [\"Zoont/faster-whisper-large-v3-turbo-int8-ct2\", \"deepdml/faster-whisper-large-v3-turbo-ct2\", \"large-v3\"]\n",
        "compute_type = \"int8_float16\" #@param [\"int8_float16\", \"float16\", \"int8\"]\n",
        "\n",
        "\n",
        "#@markdown ### 4. VAD (音声区間検出) 設定\n",
        "#@markdown ---\n",
        "#@markdown VADを有効にすると、無音区間を自動で除去し、文字起こしの精度を向上させることができます。\n",
        "use_vad_filter = True #@param {type:\"boolean\"}\n",
        "#@markdown ここで指定したミリ秒以上の無音を「発話の区切り」とみなします。\n",
        "vad_min_silence_duration_ms = 500 #@param {type:\"slider\", min:100, max:2000, step:100}\n",
        "\n",
        "# --- ここから下は実行コード（編集不要） ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def get_timestamp():\n",
        "    \"\"\"現在時刻をフォーマットして返す\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "def save_transcription_result(segments_generator, output_path):\n",
        "    \"\"\"文字起こし結果(ジェネレータ)をファイルに書き出す関数\"\"\"\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for segment in segments_generator:\n",
        "            line = f\"[{segment.start:0>7.2f}s -> {segment.end:0>7.2f}s] {segment.text.strip()}\\n\"\n",
        "            f.write(line)\n",
        "\n",
        "# 1. 環境設定とディレクトリの準備\n",
        "print(f\"[{get_timestamp()}] --- 1. 環境設定とディレクトリの準備 ---\")\n",
        "os.makedirs(drive_audio_input_dir, exist_ok=True)\n",
        "os.makedirs(drive_transcript_output_dir, exist_ok=True)\n",
        "print(f\"入力フォルダ: {drive_audio_input_dir}\")\n",
        "print(f\"出力フォルダ: {drive_transcript_output_dir}\")\n",
        "\n",
        "# 2. モデルのロード\n",
        "print(f\"\\n[{get_timestamp()}] --- 2. モデル '{model_name}' ({compute_type}) をロード中... ---\")\n",
        "start_load_time = time.time()\n",
        "model = WhisperModel(model_name, device=\"cuda\", compute_type=compute_type)\n",
        "end_load_time = time.time()\n",
        "print(f\"✅ モデルのロードが完了しました。({end_load_time - start_load_time:.2f}秒)\")\n",
        "\n",
        "# 3. 処理対象ファイルの検索と選択\n",
        "print(f\"\\n[{get_timestamp()}] --- 3. 処理対象ファイルの選択 ---\")\n",
        "supported_audio_formats = ['*.mp3', '*.wav', '*.m4a', '*.flac', '*.ogg', '*.opus']\n",
        "supported_video_formats = ['*.mp4', '*.mov', '*.avi', '*.wmv']\n",
        "all_media_files = []\n",
        "for fmt in supported_audio_formats + supported_video_formats:\n",
        "    all_media_files.extend(glob.glob(os.path.join(drive_audio_input_dir, fmt)))\n",
        "\n",
        "files_to_process = []\n",
        "if processing_mode == \"特定の１ファイルのみ処理\":\n",
        "    target_path = os.path.join(drive_audio_input_dir, specific_filename)\n",
        "    if target_path in all_media_files:\n",
        "        files_to_process.append(target_path)\n",
        "        print(f\"✅ 特定ファイルモード: '{specific_filename}' を処理対象とします。\")\n",
        "    else:\n",
        "        print(f\"⚠️ エラー: 指定されたファイル '{specific_filename}' が入力フォルダ内に見つかりません。\")\n",
        "else:\n",
        "    files_to_process = all_media_files\n",
        "    print(f\"✅ {len(files_to_process)} 件の全ファイルを処理対象とします。\")\n",
        "\n",
        "# 4. メイン処理\n",
        "if not files_to_process:\n",
        "    print(\"\\n--- 処理対象ファイルがないため、終了します。 ---\")\n",
        "else:\n",
        "    print(f\"\\n[{get_timestamp()}] --- 4. 文字起こし処理開始 ---\")\n",
        "    overall_start_time = time.time()\n",
        "\n",
        "    # tqdmを使用してプログレスバーを表示\n",
        "    for audio_path_drive in tqdm(files_to_process, desc=\"Overall Progress\"):\n",
        "        start_process_time = time.time()\n",
        "        filename = os.path.basename(audio_path_drive)\n",
        "        base_filename, file_extension = os.path.splitext(filename)\n",
        "        print(f\"\\n[{get_timestamp()}] 処理開始: {filename}\")\n",
        "\n",
        "        local_media_path = None\n",
        "        temp_audio_file = None\n",
        "        path_to_transcribe = None\n",
        "\n",
        "        try:\n",
        "            # 元ファイルをローカルにコピー\n",
        "            local_media_path = os.path.join('/content/', filename)\n",
        "            shutil.copy(audio_path_drive, local_media_path)\n",
        "            print(f\"  - ファイルをローカルにコピーしました。\")\n",
        "\n",
        "            # 動画ファイルかどうかを判定\n",
        "            if file_extension.lower() in [ext.strip('*') for ext in supported_video_formats]:\n",
        "                print(f\"  - 動画ファイルを検出。音声を抽出します...\")\n",
        "                # 抽出後の音声ファイルパスを定義\n",
        "                temp_audio_file = os.path.join('/content/', f\"{base_filename}.mp3\")\n",
        "                # FFmpegコマンドを構築（-y:上書き, -i:入力, -vn:ビデオ無効, -ar:サンプルレート, -ac:チャンネル数, -loglevel:ログレベル）\n",
        "                ffmpeg_command = f'ffmpeg -y -i \"{local_media_path}\" -vn -ar 16000 -ac 1 -loglevel error \"{temp_audio_file}\"'\n",
        "                # コマンド実行\n",
        "                os.system(ffmpeg_command)\n",
        "                path_to_transcribe = temp_audio_file\n",
        "                print(f\"  - 音声の抽出が完了 -> {os.path.basename(temp_audio_file)}\")\n",
        "            else:\n",
        "                # 音声ファイルの場合はそのまま処理\n",
        "                path_to_transcribe = local_media_path\n",
        "\n",
        "            # 文字起こし実行\n",
        "            print(f\"  - 文字起こしを実行中...\")\n",
        "            segments, info = model.transcribe(\n",
        "                path_to_transcribe,\n",
        "                beam_size=5,\n",
        "                vad_filter=use_vad_filter,\n",
        "                vad_parameters=dict(min_silence_duration_ms=vad_min_silence_duration_ms)\n",
        "            )\n",
        "            print(f\"  - 検出言語: {info.language} (確率: {info.language_probability:.2f})\")\n",
        "\n",
        "            # 結果を保存\n",
        "            output_txt_filename = f\"{base_filename}.txt\"\n",
        "            local_output_path = os.path.join('/content/', output_txt_filename)\n",
        "            drive_output_path = os.path.join(drive_transcript_output_dir, output_txt_filename)\n",
        "\n",
        "            save_transcription_result(segments, local_output_path)\n",
        "\n",
        "            shutil.move(local_output_path, drive_output_path)\n",
        "            print(f\"  - 結果を保存しました: {drive_output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  - 💥 エラーが発生しました: {e}\")\n",
        "        finally:\n",
        "            # 一時ファイルをクリーンアップ\n",
        "            if local_media_path and os.path.exists(local_media_path):\n",
        "                os.remove(local_media_path)\n",
        "            if temp_audio_file and os.path.exists(temp_audio_file):\n",
        "                os.remove(temp_audio_file)\n",
        "            end_process_time = time.time()\n",
        "            print(f\"  - 処理完了 ({end_process_time - start_process_time:.2f}秒)\")\n",
        "\n",
        "    overall_end_time = time.time()\n",
        "    print(f\"\\n[{get_timestamp()}] --- 🎉 全てのファイルの処理が完了しました (合計所要時間: {overall_end_time - overall_start_time:.2f}秒) ---\")"
      ],
      "metadata": {
        "id": "jIuTskCrlQCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
